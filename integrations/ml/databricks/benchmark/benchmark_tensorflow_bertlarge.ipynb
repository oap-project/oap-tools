{"cells":[{"cell_type":"code","source":["%sh\n\n# BERT-Large Inference\n\n# Install necessary package\nsudo apt-get update\nsudo apt-get install zip -y\nsudo apt-get -y install git\nsudo apt-get install -y numactl\n\n# Remove old materials if exist\nrm -rf /TF/\nmkdir /TF/\n\n# Create ckpt directory\nmkdir -p /TF/BERT-Large-output/\nexport BERT_LARGE_OUTPUT=/TF/BERT-Large-output/\n\n# Download IntelAI benchmark\ncd /TF/\nwget https://github.com/IntelAI/models/archive/refs/tags/v1.8.1.zip\nunzip v1.8.1.zip\ncd /TF/models-1.8.1/\n\n\nexport SQUAD_DIR=/dbfs/home/TF/bert-large/SQuAD-1.1/\nexport BERT_LARGE_DIR=/dbfs/home/TF/bert-large/\n\nexport PYTHONPATH=$PYTHONPATH:.\n\n# Launch Benchmark for inference\n\nnuma_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\n\n\n       \nfunction run_inference_without_numabind() {\n  cd /TF/models-1.8.1/benchmarks/\n  python3 launch_benchmark.py \\\n    --model-name=bert_large \\\n    --precision=fp32 \\\n    --mode=inference \\\n    --framework=tensorflow \\\n    --batch-size=32 \\\n    --data-location $BERT_LARGE_DIR/wwm_uncased_L-24_H-1024_A-16 \\\n    --checkpoint $BERT_LARGE_DIR/bert_large_checkpoints \\\n    --output-dir $BERT_LARGE_OUTPUT/bert-squad-output \\\n    --verbose \\\n    -- infer_option=SQuAD \\\n       DEBIAN_FRONTEND=noninteractive \\\n       predict_file=$SQUAD_DIR/dev-v1.1.json \\\n       experimental-gelu=False \\\n       init_checkpoint=model.ckpt-3649\n}\n\nfunction run_inference_with_numabind() {\n  cd /TF/models-1.8.1/benchmarks/\n  nohup python3 launch_benchmark.py \\\n    --model-name=bert_large \\\n    --precision=fp32 \\\n    --mode=inference \\\n    --framework=tensorflow \\\n    --batch-size=32 \\\n    --socket-id 0  \\\n    --data-location $BERT_LARGE_DIR/wwm_uncased_L-24_H-1024_A-16 \\\n    --checkpoint $BERT_LARGE_DIR/bert_large_checkpoints \\\n    --output-dir $BERT_LARGE_OUTPUT/bert-squad-output \\\n    --verbose \\\n    -- infer_option=SQuAD \\\n       DEBIAN_FRONTEND=noninteractive \\\n       predict_file=$SQUAD_DIR/dev-v1.1.json \\\n       experimental-gelu=False \\\n       init_checkpoint=model.ckpt-3649 >> socket0-inference-log &\n       \n  nohup python3 launch_benchmark.py \\\n    --model-name=bert_large \\\n    --precision=fp32 \\\n    --mode=inference \\\n    --framework=tensorflow \\\n    --batch-size=32 \\\n    --socket-id 1 \\\n    --data-location $BERT_LARGE_DIR/wwm_uncased_L-24_H-1024_A-16 \\\n    --checkpoint $BERT_LARGE_DIR/bert_large_checkpoints \\\n    --output-dir $BERT_LARGE_OUTPUT/bert-squad-output \\\n    --verbose \\\n    -- infer_option=SQuAD \\\n       DEBIAN_FRONTEND=noninteractive \\\n       predict_file=$SQUAD_DIR/dev-v1.1.json \\\n       experimental-gelu=False \\\n       init_checkpoint=model.ckpt-3649 >> socket1-inference-log &\n}\n\nif [ \"$numa_nodes\" = \"1\" ];then\n        run_inference_without_numabind\nelse\n        run_inference_with_numabind\nfi\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a631848-2959-4fed-8510-465edf8f6103"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n# Get the inference result\nnuma_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\nif [ \"$numa_nodes\" = \"1\" ];then\n        cd /TF/BERT-Large-output/bert-squad-output/\n        cat benchmark*.log | grep \"throughput((num_processed_examples-threshod_examples)/Elapsedtime)\"\nelse\n        cd /TF/models-1.8.1/benchmarks/\n        cat socket*-log | grep \"throughput((num_processed_examples-threshod_examples)/Elapsedtime)\"\nfi\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f76efe7-140c-46b9-ab6b-f17475fedd81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh\n\n# BERT-Large Training\n\n# Install necessary package\nsudo apt-get update\nsudo apt-get install zip -y\nsudo apt-get -y install git\nsudo apt-get install -y libblacs-mpi-dev\nsudo apt-get install -y numactl\n\n# Remove old materials if exist\nrm -rf /TF/\nmkdir /TF/\n\n# Create ckpt directory\nmkdir -p /TF/BERT-Large-output/\nexport BERT_LARGE_OUTPUT=/TF/BERT-Large-output/\n\n# Download IntelAI benchmark\ncd /TF/\nwget https://github.com/IntelAI/models/archive/refs/tags/v1.8.1.zip\nunzip v1.8.1.zip\ncd models-1.8.1/\n\nexport SQUAD_DIR=/dbfs/home/TF/bert-large/SQuAD-1.1\nexport BERT_LARGE_MODEL=/dbfs/home/TF/bert-large/wwm_uncased_L-24_H-1024_A-16\n\nexport PYTHONPATH=$PYTHONPATH:.\n\ncores_per_socket=$(lscpu | awk '/^Core\\(s\\) per socket/{ print $4 }')\nnuma_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\n\n# Launch Benchmark for training\ncd /TF/models-1.8.1/benchmarks/\n\nfunction run_training_without_numabind() {\n  python launch_benchmark.py \\\n    --model-name=bert_large \\\n    --precision=fp32 \\\n    --mode=training \\\n    --framework=tensorflow \\\n    --batch-size=4 \\\n    --benchmark-only \\\n    --data-location=$BERT_LARGE_MODEL \\\n    -- train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_MODEL/bert_config.json   init_checkpoint=$BERT_LARGE_MODEL/bert_model.ckpt     vocab_file=$BERT_LARGE_MODEL/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=0.1     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True\n}\n\nfunction run_training_with_numabind() {\n  intra_thread=`expr $cores_per_socket - 2`\n  python launch_benchmark.py \\\n    --model-name=bert_large \\\n    --precision=fp32 \\\n    --mode=training \\\n    --framework=tensorflow \\\n    --batch-size=4 \\\n    --mpi_num_processes=$numa_nodes \\\n    --num-intra-threads=$intra_thread \\\n    --num-inter-threads=1 \\\n    --benchmark-only \\\n    --data-location=$BERT_LARGE_MODEL \\\n    -- train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_MODEL/bert_config.json init_checkpoint=$BERT_LARGE_MODEL/bert_model.ckpt     vocab_file=$BERT_LARGE_MODEL/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=0.1     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True\n}\n\nif [ \"$numa_nodes\" = \"1\" ];then\n        run_training_without_numabind\nelse\n        run_training_with_numabind\nfi\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96f083b7-e3a3-4cdf-8474-7f304b641fd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Print version, and check whether is intel-optimized\nimport tensorflow\nprint(\"tensorflow version: \" + tensorflow.__version__)\n\nfrom packaging import version\nif (version.parse(\"2.5.0\") <= version.parse(tensorflow.__version__)):\n  from tensorflow.python.util import _pywrap_util_port\n  print( _pywrap_util_port.IsMklEnabled())\nelse:\n  from tensorflow.python import _pywrap_util_port\n  print(_pywrap_util_port.IsMklEnabled())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df28a683-ad6d-4af5-8eb7-b3d46453c165"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"benchmark_tensorflow_bertlarge","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2862803776862941}},"nbformat":4,"nbformat_minor":0}
